# Dialog policy optimization in low resource setting

![project] ![research]



- <b>Project Lead(s) / Mentor(s)</b>
    1. Name (talk forum profile link)
    2. Name (talk forum profile link)
- <b>Contributor(s)</b>
    1. Name (talk forum profile link)
    2. Name (talk forum profile link)

<b>Usefull Links </b>

- GitHub : <project_url>
- Talk Forum : <talk_forum_link>

---

## Summary

The dialogue policy optimization is an open-research problem and currently, the state of the art methods have been based on Reinforcement Learning(RL). However, RL based methods tend to overfit in a low resource setting. We are introducing a novel probability-based method to address the overfitting problem. Since this methodology applies to a low amount of samples, this method can lead to an insufficient exploration of agendas by the agent. Therefore we further developed the methodology by introducing a selective sampling method based on the reward function that prioritizes the failed dialog acts, where the agent actively decides what agendas to use.

## Description

Detailed description of your project.

- Project phases
- Diagrams
- Approches

## More references

1. Reference
2. Link

---

### License

Apache License 2.0

### Code of Conduct

Please read our [code of conduct document here](https://github.com/aaivu/aaivu-introduction/blob/master/docs/code_of_conduct.md).

[project]: https://img.shields.io/badge/-Project-blue
[research]: https://img.shields.io/badge/-Research-yellowgreen
